{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './fig4/airplane_1.jpg'\n",
    "\n",
    "img = cv2.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dnn model import\n",
    "\n",
    "model = './googlenet/bvlc_googlenet.caffemodel'\n",
    "config = './googlenet/deploy.prototxt'\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if net.empty():\n",
    "    print('model load fail')\n",
    "    sys.exit\n",
    "\n",
    "class_name = []\n",
    "with open('./googlenet/classification_classes_ILSVRC2012.txt', 'rt') as f:\n",
    "    class_name = f.read().rstrip('\\n').split('\\n')\n",
    "    \n",
    "class_name\n",
    "len(class_name)\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (224, 224), (104, 117, 123),\n",
    "                             swapRB = False)\n",
    "net.setInput(blob)\n",
    "prob = net.forward()\n",
    "prob.shape\n",
    "\n",
    "\n",
    "##\n",
    "out = prob.flatten()\n",
    "classid = np.argmax(out)\n",
    "ClassName = class_name[classid]\n",
    "confidence = out[classid]\n",
    "\n",
    "# out.shape\n",
    "text = f'{ClassName}, {confidence*100:.2f}%'\n",
    "\n",
    "cv2.putText(img, text, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 0.8,\n",
    "            (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## onnx\n",
    "\n",
    "model_onnx = './googlenet/googlenet-3.onnx'\n",
    "config = ''\n",
    "\n",
    "net = cv2.dnn.readNet(model_onnx, config)\n",
    "\n",
    "if net.empty():\n",
    "    print('model load fail')\n",
    "    sys.exit\n",
    "\n",
    "class_name = []\n",
    "with open('./googlenet/classification_classes_ILSVRC2012.txt', 'rt') as f:\n",
    "    class_name = f.read().rstrip('\\n').split('\\n')\n",
    "    \n",
    "class_name\n",
    "len(class_name)\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (224, 224), (104, 117, 123),\n",
    "                             swapRB = False)\n",
    "net.setInput(blob)\n",
    "prob = net.forward()\n",
    "prob.shape\n",
    "\n",
    "\n",
    "##\n",
    "out = prob.flatten()\n",
    "classid = np.argmax(out)\n",
    "ClassName = class_name[classid]\n",
    "confidence = out[classid]\n",
    "\n",
    "text = f'{ClassName}, {confidence*100:.2f}%'\n",
    "\n",
    "cv2.putText(img, text, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 0.8,\n",
    "            (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = glob.glob('./fig4/*.*')\n",
    "\n",
    "model = './googlenet/bvlc_googlenet.caffemodel'\n",
    "config = './googlenet/deploy.prototxt'\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "class_name = []\n",
    "with open('./googlenet/classification_classes_ILSVRC2012.txt', 'rt') as f:\n",
    "    class_name = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "idx = 0\n",
    "\n",
    "while 1:\n",
    "    img = cv2.imread(file_paths[idx])\n",
    "    blob = cv2.dnn.blobFromImage(img, 1, (224, 224), (104, 117, 123),\n",
    "                                swapRB = False)\n",
    "    net.setInput(blob)\n",
    "    prob = net.forward()\n",
    "\n",
    "    ##\n",
    "    out = prob.flatten()\n",
    "    classid = np.argmax(out)\n",
    "    ClassName = class_name[classid]\n",
    "    confidence = out[classid]\n",
    "\n",
    "    text = f'{ClassName}, {confidence*100:.2f}%'\n",
    "\n",
    "    cv2.putText(img, text, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 0.8,\n",
    "                (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('img', img)\n",
    "    if cv2.waitKey(1500) == 27:\n",
    "        break\n",
    "    \n",
    "    idx += 1\n",
    "    \n",
    "    if idx >= len(file_paths):\n",
    "        idx = 0\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "img_path = './sunglass/sunglass.png'\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "## tensor\n",
    "model_tf = './face/opencv_face_detector_uint8.pb'\n",
    "config_tf = './face/opencv_face_detector.pbtxt'\n",
    "\n",
    "face_net = cv2.dnn.readNet(model_tf, config_tf)\n",
    "\n",
    "if face_net.empty():\n",
    "    print('model load fail')\n",
    "    sys.exit\n",
    "    \n",
    "face_blob = cv2.dnn.blobFromImage(img, 1, (300, 300), (104, 177, 123),\n",
    "                             swapRB = False)\n",
    "face_net.setInput(face_blob)\n",
    "output = face_net.forward()\n",
    "\n",
    "detect = output[0, 0, :, :]\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "for i in range(detect.shape[0]):\n",
    "    confidence = detect[i, 2]\n",
    "    if confidence > 0.5:\n",
    "        x1 = int(detect[i, 3] * w)\n",
    "        y1 = int(detect[i, 4] * h)\n",
    "        x2 = int(detect[i, 5] * w)\n",
    "        y2 = int(detect[i, 6] * h)\n",
    "        \n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0 ,255), 1)\n",
    "        text = f'Face, {confidence*100:.2f}%'\n",
    "        cv2.putText(img, text, (x1, y1-2), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        \n",
    "cv2.namedWindow('img', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "## tensor\n",
    "model_caffe = './face/res10_300x300_ssd_iter_140000_fp16.caffemodel'\n",
    "config_caffe = './face/deploy.prototxt'\n",
    "face_net = cv2.dnn.readNet(model_caffe, config_caffe)\n",
    "\n",
    "if face_net.empty():\n",
    "    print('model load fail')\n",
    "    sys.exit\n",
    "    \n",
    "if not cap.isOpened():\n",
    "    print('video failed')\n",
    "    sys.exit\n",
    "    \n",
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "    face_blob = cv2.dnn.blobFromImage(frame, 1, (300, 300), (104, 177, 123), swapRB = False)\n",
    "    face_net.setInput(face_blob)\n",
    "    output = face_net.forward()\n",
    "\n",
    "    detect = output[0, 0, :, :]\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "\n",
    "    for i in range(detect.shape[0]):\n",
    "        confidence = detect[i, 2]\n",
    "        if confidence > 0.5:\n",
    "            x1 = int(detect[i, 3] * w)\n",
    "            y1 = int(detect[i, 4] * h)\n",
    "            x2 = int(detect[i, 5] * w)\n",
    "            y2 = int(detect[i, 6] * h)\n",
    "            \n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0 ,255), 1)\n",
    "            text = f'Face, {confidence*100:.2f}%'\n",
    "            cv2.putText(frame, text, (x1, y1-2), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                    (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        \n",
    "    # cv2.namedWindow('img', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "img_path = './fig2/puppy.bmp'\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "## tensor\n",
    "model_tf = './face/opencv_face_detector_uint8.pb'\n",
    "config_tf = './face/opencv_face_detector.pbtxt'\n",
    "\n",
    "face_net = cv2.dnn.readNet(model_tf, config_tf)\n",
    "\n",
    "if face_net.empty():\n",
    "    print('model load fail')\n",
    "    sys.exit\n",
    "    \n",
    "face_blob = cv2.dnn.blobFromImage(img, 1, (300, 300), (104, 177, 123),\n",
    "                             swapRB = False)\n",
    "face_net.setInput(face_blob)\n",
    "output = face_net.forward()\n",
    "\n",
    "detect = output[0, 0, :, :]\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "for i in range(detect.shape[0]):\n",
    "    confidence = detect[i, 2]\n",
    "    if confidence > 0.5:\n",
    "        x1 = int(detect[i, 3] * w)\n",
    "        y1 = int(detect[i, 4] * h)\n",
    "        x2 = int(detect[i, 5] * w)\n",
    "        y2 = int(detect[i, 6] * h)\n",
    "        \n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0 ,255), 1)\n",
    "        text = f'Face, {confidence*100:.2f}%'\n",
    "        cv2.putText(img, text, (x1, y1-2), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        \n",
    "cv2.namedWindow('img', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## yolo\n",
    "\n",
    "model = './yolov7-main/yolov7/yolov3.weights'\n",
    "config = './yolov7-main/yolov7/yolov3.cfg'\n",
    "label = './yolov7-main/yolov7/coco.names.txt'\n",
    "\n",
    "img = './yolov7-main/peoples.jpg'\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "class_name = []\n",
    "with open(label, 'rt') as f:\n",
    "    class_name = f.read().rstrip('\\n').split('\\n')\n",
    "    \n",
    "colors = np.random.uniform(0, 255, size=(80, 3))\n",
    "\n",
    "layers_name = net.getLayerNames()\n",
    "\n",
    "output_layers = [layers_name[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "\n",
    "img = cv2.imread(img)\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), mean = (0, 0, 0), swapRB = True)\n",
    "net.setInput(blob)\n",
    "outs = net.forward(output_layers)\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "\n",
    "confidence_thresh = 0.5\n",
    "nms_thresh = 0.4\n",
    "\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > confidence_thresh:\n",
    "            cx = int(detection[0] * w)\n",
    "            cy = int(detection[1] * h)\n",
    "            bw = int(detection[2] * w)\n",
    "            bh = int(detection[3] * h)\n",
    "            \n",
    "            sx = int(cx - bw / 2)\n",
    "            sy = int(cy - bh / 2)\n",
    "            \n",
    "            boxes.append([sx, sy, bw, bh])\n",
    "            confidences.append(confidence)\n",
    "            class_ids.append(class_id)\n",
    "            \n",
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, confidence_thresh, nms_thresh)\n",
    "\n",
    "for i in indices:\n",
    "    sx, sy, bw, bh = boxes[i]\n",
    "    label = f'{class_name[class_ids[i]]}, {confidences[i]*100:.2f}'\n",
    "    color = colors[class_ids[i]]\n",
    "    cv2.rectangle(img, (sx, sy, bw, bh), color, 2)\n",
    "    cv2.putText(img, label, (sx, sy - 5), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                color, 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "## yolo\n",
    "\n",
    "model = './yolov7-main/yolov7/yolov3.weights'\n",
    "config = './yolov7-main/yolov7/yolov3.cfg'\n",
    "label = './yolov7-main/yolov7/coco.names.txt'\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "class_name = []\n",
    "with open(label, 'rt') as f:\n",
    "    class_name = f.read().rstrip('\\n').split('\\n')\n",
    "    \n",
    "colors = np.random.uniform(0, 255, size=(80, 3))\n",
    "\n",
    "layers_name = net.getLayerNames()\n",
    "\n",
    "output_layers = [layers_name[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "\n",
    "\n",
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255, (416, 416), mean = (0, 0, 0), swapRB = True)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    confidence_thresh = 0.5\n",
    "    nms_thresh = 0.4\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > confidence_thresh:\n",
    "                cx = int(detection[0] * w)\n",
    "                cy = int(detection[1] * h)\n",
    "                bw = int(detection[2] * w)\n",
    "                bh = int(detection[3] * h)\n",
    "                \n",
    "                sx = int(cx - bw / 2)\n",
    "                sy = int(cy - bh / 2)\n",
    "                \n",
    "                boxes.append([sx, sy, bw, bh])\n",
    "                confidences.append(confidence)\n",
    "                class_ids.append(class_id)\n",
    "                \n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confidence_thresh, nms_thresh)\n",
    "\n",
    "    for i in indices:\n",
    "        sx, sy, bw, bh = boxes[i]\n",
    "        label = f'{class_name[class_ids[i]]}, {confidences[i]*100:.2f}'\n",
    "        color = colors[class_ids[i]]\n",
    "        cv2.rectangle(frame, (sx, sy, bw, bh), color, 2)\n",
    "        cv2.putText(frame, label, (sx, sy - 5), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                    color, 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
